{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheldonkemper/bank_of_england/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VD8ipZFGbLk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Mount Google Drive to the root location with force_remount\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Assuming 'BOE' folder is in 'MyDrive' and already shared\n",
        "BOE_path = '/content/drive/MyDrive/BOE/bank_of_england/data'\n",
        "\n",
        "# Now you (and others with access) can work with files in this directory\n",
        "# For example, you can list the contents:\n",
        "print(os.listdir(BOE_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sys.path.append('/content/drive/My Drive/bank_of_england/src')\n",
        "\n",
        "from preprocessing import preprocess_pipeline\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"JP Morgan's earnings increased by 20% in Q4 2024.\"\n",
        "processed_text = preprocess_pipeline(sample_text)\n",
        "print(processed_text)  # Output: \"jpmorgan earning increase q4\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# File path to uploaded JPMorgan transcript PDF\n",
        "pdf_path = \"/mnt/data/4q24-earnings-transcript.pdf\"\n",
        "\n",
        "# Function to extract financial quarter and call date from the first page\n",
        "def extract_financial_info(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        first_page_text = pdf.pages[0].extract_text()\n",
        "        \n",
        "        # Extract Financial Quarter (e.g., \"4Q24\")\n",
        "        financial_quarter_match = re.search(r\"(\\dQ\\d{2})\", first_page_text)\n",
        "        financial_quarter = financial_quarter_match.group(1) if financial_quarter_match else \"Unknown\"\n",
        "\n",
        "        # Extract Call Date (e.g., \"January 15, 2025\")\n",
        "        call_date_match = re.search(r\"([A-Za-z]+ \\d{1,2}, \\d{4})\", first_page_text)\n",
        "        call_date = call_date_match.group(1) if call_date_match else \"Unknown\"\n",
        "\n",
        "        return financial_quarter, call_date\n",
        "\n",
        "# Extract financial quarter and call date dynamically\n",
        "FINANCIAL_QUARTER, CALL_DATE = extract_financial_info(pdf_path)\n",
        "\n",
        "import pdfplumber\n",
        "import re\n",
        "\n",
        "# Function to extract and clean text from the PDF\n",
        "def extract_clean_text(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        text_data = []\n",
        "        \n",
        "        # Skip the first page and process remaining pages\n",
        "        for i, page in enumerate(pdf.pages[1:]):  # Skipping first page\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                # Remove headers, footers, and page numbers\n",
        "                text = re.sub(r\"JPMorgan Chase & Co\\..*\", \"\", text)  # Remove headers\n",
        "                text = re.sub(r\"Page \\d+ of \\d+\", \"\", text)  # Remove footers\n",
        "                text = re.sub(r\"Copyright Â© \\d{4} JPMorgan Chase & Co\\.\", \"\", text)  # Remove copyright notices\n",
        "                \n",
        "                # Preserve new lines to ensure correct speaker separation\n",
        "                text_data.append(text.strip())\n",
        "\n",
        "        # Join extracted text with explicit new lines for proper structure\n",
        "        full_text = \"\\n\".join(text_data)\n",
        "\n",
        "        # Remove standalone page numbers (if appearing alone on a line)\n",
        "        full_text = re.sub(r\"\\n\\d+\\n\", \"\\n\", full_text)\n",
        "\n",
        "        # Fix text split across pages:\n",
        "        # Remove hyphenation at line breaks (e.g., \"finan-\\ncial\" -> \"financial\")\n",
        "        full_text = re.sub(r\"(?<=\\w)-\\n(?=\\w)\", \"\", full_text)\n",
        "\n",
        "        # Merge text broken across pages while preserving speaker names\n",
        "        full_text = re.sub(r\"(?<!\\n[A-Z][A-Za-z\\s]+:\\s)\\n\", \" \", full_text)\n",
        "\n",
        "        # Remove disclaimers section at the end of the document\n",
        "        disclaimer_match = re.search(r\"Disclaimer\\s+This document contains forward-looking statements.*?JPMorgan Chase & Co\\. does not undertake to update any forward-looking statements\",\n",
        "                                     full_text, re.IGNORECASE | re.DOTALL)\n",
        "        if disclaimer_match:\n",
        "            full_text = full_text[:disclaimer_match.start()].strip()  # Remove disclaimer section\n",
        "\n",
        "        return full_text\n",
        "\n",
        "\n",
        "# Extract and clean the text\n",
        "cleaned_text = extract_clean_text(pdf_path)\n",
        "\n",
        "# Split the transcript into Presentation and Q&A sections\n",
        "qna_start_match = re.search(r\"QUESTION AND ANSWER SECTION\", cleaned_text, re.IGNORECASE)\n",
        "if qna_start_match:\n",
        "    presentation_text = cleaned_text[:qna_start_match.start()].strip()\n",
        "    qna_text = cleaned_text[qna_start_match.start():].strip()\n",
        "else:\n",
        "    presentation_text = cleaned_text\n",
        "    qna_text = \"\"\n",
        "\n",
        "# Function to clean text while preserving alignment of speaker-comment pairs\n",
        "def clean_text_preserving_speaker_alignment(text):\n",
        "    \"\"\"\n",
        "    Cleans extracted text by removing page numbers and merging text split across page breaks\n",
        "    while ensuring speaker-comment alignment is maintained.\n",
        "    \"\"\"\n",
        "    # Remove standalone page numbers appearing alone on a line\n",
        "    text = re.sub(r\"\\n\\d+\\n\", \"\\n\", text)\n",
        "\n",
        "    # Preserve actual speaker name and job title by ensuring they don't get merged incorrectly\n",
        "    text = re.sub(r\"\\n(?=[A-Z][A-Za-z\\s]+\\n[A-Za-z\\s,]+)\", \" NEW_SPEAKER_MARKER \", text)  # Mark new speakers\n",
        "    \n",
        "    # Merge broken sentences split across pages without affecting new speakers\n",
        "    text = re.sub(r\"(?<!NEW_SPEAKER_MARKER)\\n\", \" \", text)  \n",
        "\n",
        "    # Restore proper formatting for new speakers\n",
        "    text = text.replace(\" NEW_SPEAKER_MARKER \", \"\\n\")\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# Apply improved page break handling\n",
        "presentation_text_fixed = clean_text_preserving_speaker_alignment(presentation_text)\n",
        "qna_text_fixed = clean_text_preserving_speaker_alignment(qna_text)\n",
        "\n",
        "# Function to extract structured presentation data\n",
        "def extract_presentation_data(text):\n",
        "    \"\"\"\n",
        "    Extracts speaker names, job titles, and remarks while preserving alignment.\n",
        "    \"\"\"\n",
        "    pattern = re.compile(\n",
        "        r\"([A-Z][A-Za-z\\s]+)\\n([A-Za-z\\s,]+)\\n(.+?)(?=\\n[A-Z][A-Za-z\\s]+\\n[A-Za-z\\s,]+|\\Z)\",\n",
        "        re.DOTALL,\n",
        "    )\n",
        "    matches = pattern.findall(text)\n",
        "\n",
        "    data = []\n",
        "    for speaker, title, speech in matches:\n",
        "        speech = \" \".join(speech.splitlines())  # Merge broken lines\n",
        "        speaker = speaker.strip()\n",
        "        title = title.strip()\n",
        "\n",
        "        data.append({\n",
        "            \"Financial_Quarter\": FINANCIAL_QUARTER,\n",
        "            \"Call_Date\": CALL_DATE,\n",
        "            \"Speaker\": speaker,\n",
        "            \"Job_Title\": title,\n",
        "            \"Text\": speech.strip(),\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Function to extract structured Q&A data\n",
        "def extract_qna_data(text):\n",
        "    \"\"\"\n",
        "    Extracts structured Q&A data, ensuring alignment of questions and answers.\n",
        "    \"\"\"\n",
        "    pattern = re.compile(\n",
        "        r\"([A-Z][A-Za-z\\s]+)\\n([A-Za-z\\s,]+)\\n(.+?)(?=\\n[A-Z][A-Za-z\\s]+\\n[A-Za-z\\s,]+|\\Z)\",\n",
        "        re.DOTALL,\n",
        "    )\n",
        "    matches = pattern.findall(text)\n",
        "\n",
        "    data = []\n",
        "    is_question = True  # Toggle between Question and Answer\n",
        "\n",
        "    for speaker, title, speech in matches:\n",
        "        speech = \" \".join(speech.splitlines())  # Merge broken lines\n",
        "        qna_type = \"Question\" if is_question else \"Answer\"\n",
        "        data.append({\n",
        "            \"Financial_Quarter\": FINANCIAL_QUARTER,\n",
        "            \"Call_Date\": CALL_DATE,\n",
        "            \"Speaker\": speaker.strip(),\n",
        "            \"Job_Title\": title.strip(),\n",
        "            \"Type\": qna_type,\n",
        "            \"Text\": speech.strip(),\n",
        "        })\n",
        "        is_question = not is_question  # Toggle between Question and Answer\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Process Presentation and Q&A Data\n",
        "presentation_df = extract_presentation_data(presentation_text_fixed)\n",
        "qna_df = extract_qna_data(qna_text_fixed)\n",
        "\n",
        "# Save the cleaned data to CSV files\n",
        "presentation_csv_path = \"/mnt/data/jpm_presentation.csv\"\n",
        "qna_csv_path = \"/mnt/data/jpm_qna.csv\"\n",
        "\n",
        "presentation_df.to_csv(presentation_csv_path, index=False)\n",
        "qna_df.to_csv(qna_csv_path, index=False)\n",
        "\n",
        "# Display the cleaned data for review\n",
        "import ace_tools as tools\n",
        "tools.display_dataframe_to_user(name=\"Final JPMorgan Presentation Data\", dataframe=presentation_df)\n",
        "tools.display_dataframe_to_user(name=\"Final JPMorgan Q&A Data\", dataframe=qna_df)\n",
        "\n",
        "# Return file paths for download\n",
        "presentation_csv_path, qna_csv_path\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOG0FwzpZ653agZl1bU9SaP",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
