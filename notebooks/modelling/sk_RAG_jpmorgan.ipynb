{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheldonkemper/bank_of_england/blob/main/notebooks/modelling/sk_RAG_jpmorgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "2C9SSNHREALD",
        "outputId": "189e29d1-ae16-49c1-a2e3-797bfc1c7c17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n===================================================\\nAuthor: Sheldon Kemper\\nRole: Data Engineering Lead, Bank of England Employer Project (Quant Collective)\\nLinkedIn: https://www.linkedin.com/in/sheldon-kemper\\nDate: 2025-02-04\\nVersion: 1.1\\n\\nDescription:\\n    This notebook implements a Retrieval-Augmented Generation (RAG) system using JP Morgan\\n    earnings transcripts as the source data. It builds on our existing data engineering pipeline\\n    by reading raw PDF files stored in Google Drive, extracting text using LangChain’s PyPDFLoader,\\n    and indexing the content with CHROMA and Sentence Transformer embeddings. A text generation model\\n    (Flan-T5) is then used to answer queries based on the retrieved context, and the functionality\\n    is wrapped as a tool for a LangChain agent to handle more complex interactions.\\n\\n===================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "===================================================\n",
        "Author: Sheldon Kemper\n",
        "Role: Data Engineering Lead, Bank of England Employer Project (Quant Collective)\n",
        "LinkedIn: https://www.linkedin.com/in/sheldon-kemper\n",
        "Date: 2025-02-04\n",
        "Version: 1.1\n",
        "\n",
        "Description:\n",
        "    This notebook implements a Retrieval-Augmented Generation (RAG) system using JP Morgan\n",
        "    earnings transcripts as the source data. It builds on our existing data engineering pipeline\n",
        "    by reading raw PDF files stored in Google Drive, extracting text using LangChain’s PyPDFLoader,\n",
        "    and indexing the content with CHROMA and Sentence Transformer embeddings. A text generation model\n",
        "    (Flan-T5) is then used to answer queries based on the retrieved context, and the functionality\n",
        "    is wrapped as a tool for a LangChain agent to handle more complex interactions.\n",
        "\n",
        "===================================================\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up and Import Libraries"
      ],
      "metadata": {
        "id": "HsOlVscFP8bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U langchain-community\n",
        "# !pip install pypdf\n",
        "# !pip install chromadb"
      ],
      "metadata": {
        "id": "4uTGf-avQdHP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import required libraries"
      ],
      "metadata": {
        "id": "4dnA9VlNUcLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import pipeline\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.vectorstores import Chroma\n",
        "from google.colab import drive\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF')  # <-- Replace with your token"
      ],
      "metadata": {
        "id": "POMlE--4UgTD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "6m9KlYOGUjfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set the raw directory (adjust if necessary)\n",
        "raw_dir = \"/content/drive/MyDrive/BOE/bank_of_england/data/raw/jpmorgan\"\n",
        "\n",
        "# List all PDF files in the raw directory\n",
        "pdf_files = [os.path.join(raw_dir, file) for file in os.listdir(raw_dir) if file.endswith(\".pdf\")]\n",
        "print(f\"Found {len(pdf_files)} PDF files in {raw_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pgXUITkP4yZ",
        "outputId": "33ef635e-63af-4088-ffa1-932245bf1f49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 8 PDF files in /content/drive/MyDrive/BOE/bank_of_england/data/raw/jpmorgan\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}