{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheldonkemper/bank_of_england/blob/main/notebooks/modelling/ob_flan_t5_sentiment_jpm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym8RIzXNhpX5"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "===================================================\n",
        "Author: Oscar Bowden\n",
        "Role: Research Lead, Bank of England Employer Project (Quant Collective)\n",
        "LinkedIn: https://uk.linkedin.com/in/oscar-bowden-4b14711b7\n",
        "Date: 2025-02-24\n",
        "Version: 2.3\n",
        "\n",
        "Description:\n",
        "    This notebook contains an inference pipeline for a Flan-T5 (base)\n",
        "    model that has been fine-tuned for polar sentiment analysis\n",
        "    of financial sentences (using Financial Phrasebank:\n",
        "    https://huggingface.co/datasets/takala/financial_phrasebank).\n",
        "===================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhLPtVR3bVl9"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "mcN0DMpkEcn0"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn datsets transformers torch evaluate scikit-learn > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7SH5v9iViB1",
        "outputId": "2484310e-ce6b-4c14-f904-caebd92ccf3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "#Imports\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from umap import UMAP\n",
        "import hdbscan\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "import gc\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI665hStbfV8"
      },
      "source": [
        "# Data loading and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uDBFS9QLw1Sr",
        "outputId": "45a8e5cb-5518-4d87-92be-2679a0bbb15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load topic modelled data (management and Q&A)\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = \"/content/drive/MyDrive/JPMorgan_qna_answer_topics_by_quarter_gpt.csv\"\n",
        "#path2 = \"/content/drive/MyDrive/bank_of_england/data/preprocessed_data/\"\n",
        "\n",
        "df_q = pd.read_csv(path1)\n",
        "#df_m = pd.read_csv(path2)"
      ],
      "metadata": {
        "id": "EcpEY7LnJQ7y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning dataset\n",
        "\n",
        "df_q.drop(columns=['Sentiment'], inplace=True)"
      ],
      "metadata": {
        "id": "W9x9v-97KJS3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare topics for input into fine-tuned flan-t5\n",
        "\n",
        "def prepare_text_for_inference(text):\n",
        "    text = str(text).strip()\n",
        "    return f\"Classify sentiment: {text}\"\n",
        "\n",
        "df_q[\"snippet_infer\"] = df_q[\"Snippet\"].apply(prepare_text_for_inference)\n",
        "\n",
        "df_q[\"topic_infer\"] = df_q[\"Topic\"].apply(prepare_text_for_inference)"
      ],
      "metadata": {
        "id": "EdRvZDsZ8Izi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P0GD-CgpZ46"
      },
      "source": [
        "# 3) Inference on fine-tuned Flan-T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YxWQPZoKs9yZ"
      },
      "outputs": [],
      "source": [
        "# Load fine-tuned model and tokeniser from the best checkpoint\n",
        "\n",
        "best_checkpoint = \"/content/drive/MyDrive/bank_of_england/data/model_outputs/flan_t5_sent\"\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(best_checkpoint)\n",
        "tokenizer = T5Tokenizer.from_pretrained(best_checkpoint)\n",
        "\n",
        "# Define the prediction function using your fine-tuned model\n",
        "def predict_sentiment(prepared_text):\n",
        "    \"\"\"\n",
        "    Predicts sentiment using the fine-tuned Flan-T5 model.\n",
        "    Assumes the input text is already preprocessed (i.e., prompt prepended).\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prepared_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=2)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "# Apply inference on your prepared quarterly data\n",
        "df_q[\"topic_sent\"] = df_q[\"topic_infer\"].apply(predict_sentiment)\n",
        "df_q[\"snippet_sent\"] = df_q[\"snippet_infer\"].apply(predict_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_q[\"topic_sent\"] = df_q[\"topic_sent\"].map({\"0\": \"Negative\", \"1\": \"Neutral\", \"2\": \"Positive\"})\n",
        "df_q[\"snippet_sent\"] = df_q[\"snippet_sent\"].map({\"0\": \"Negative\", \"1\": \"Neutral\", \"2\": \"Positive\"})\n",
        "\n",
        "df_q.drop(columns=['snippet_infer', 'topic_infer'], inplace=True)"
      ],
      "metadata": {
        "id": "hb59khjaNVd7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_q[\"topic_sent\"].value_counts())\n",
        "print(f\"\\n {df_q['snippet_sent'].value_counts()}\")"
      ],
      "metadata": {
        "id": "Q2QYhtPfNqVx",
        "outputId": "88e0179f-4617-4a5d-f3ac-93db5e16446f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic_sent\n",
            "Neutral     370\n",
            "Positive     36\n",
            "Negative      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            " snippet_sent\n",
            "Neutral     258\n",
            "Positive    114\n",
            "Negative     36\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save csv\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/bank_of_england/data/model_outputs/sent_output/JPM_answers_sent_output_040325_v1.csv\"\n",
        "\n",
        "df_q.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "id": "SvS3Ie5VRgYu"
      },
      "execution_count": 28,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}