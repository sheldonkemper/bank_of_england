{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheldonkemper/bank_of_england/blob/tidy_up_preprocessing_notebook/notebooks/processed/ct_preprocessing_jpmorgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "===================================================\n",
        "Author: Chiaki Tachikawa\n",
        "Role: Data Science Lead, Bank of England Employer Project (Quant Collective)\n",
        "LinkedIn: https://www.linkedin.com/in/chiaki-tachikawa\n",
        "Date: 2025-02-27\n",
        "Version: 1.1\n",
        "\n",
        "Description:\n",
        "    This notebook implements a system for cleaning and exporting transcript data for the Bank of England project. The workflow includes:\n",
        "    - Importing necessary libraries and downloading NLTK data.\n",
        "    - Defining and applying a `preprocessor` function to clean and tokenize text data.\n",
        "    - Reading and preprocessing various CSV files containing transcript data.\n",
        "    - Exporting the preprocessed data to new CSV files for further analysis.\n",
        "\n",
        "===================================================\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a0mvZu8vposg",
        "outputId": "5442237c-8503-4bdb-bb06-792cc3c093bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n===================================================\\nAuthor: Chiaki Tachikawa\\nRole: Data Science Lead, Bank of England Employer Project (Quant Collective)\\nLinkedIn: https://www.linkedin.com/in/chiaki-tachikawa\\nDate: 2025-02-27\\nVersion: 1.1\\n\\nDescription:\\n    This notebook implements a system for cleaning and exporting transcript data for the Bank of England project. The workflow includes:\\n    - Importing necessary libraries and downloading NLTK data.\\n    - Defining and applying a `preprocessor` function to clean and tokenize text data.\\n    - Reading and preprocessing various CSV files containing transcript data.\\n    - Exporting the preprocessed data to new CSV files for further analysis.\\n\\n===================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Library**"
      ],
      "metadata": {
        "id": "-IEHW36t7eQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from collections import Counter\n",
        "import regex as re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "xQcJK0Z0cjWz",
        "outputId": "0407faa3-8924-455c-c0fc-af39b04befeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Function**"
      ],
      "metadata": {
        "id": "hgTWwaKXcc2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessor function : The function modifies the DataFrame data in place, adding two new columns (col1 and col2) with preprocessed text.\n",
        "\n",
        "\n",
        "Input:\n",
        "  - name of dataframe\n",
        "  - name of column which contains the text to clean\n",
        "  - name of column which is tokenized\n",
        "  - name of column which is cleaned"
      ],
      "metadata": {
        "id": "V-ahCZonpyuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create function to preprocess data\n",
        "def preprocessor (data, col, col1,col2):\n",
        "  #Copy col1umn\n",
        "  data[col1]=data[col]\n",
        "  data[col2]=data[col]\n",
        "\n",
        "\n",
        "  #Adding column1\n",
        "  #Lower the lettercase\n",
        "  data[col1] = data[col1].str.lower()\n",
        "\n",
        "  #Remove stop words\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  data[col1] = data[col1].apply(lambda x: \" \".join([word for word in str(x).split() if word not in (stop_words)]))\n",
        "\n",
        "  #Tokenize the word\n",
        "  data[col1] = data[col1].apply(nltk.word_tokenize)\n",
        "\n",
        "  #Remove numbers\n",
        "  data[col1] = data[col1].apply(lambda x: [word for word in x if not word.isdigit()])\n",
        "\n",
        "  #remove symbol from comments\n",
        "  data[col1] = data[col1].apply(lambda x: [word for word in x if x!=\"\"])\n",
        "\n",
        "  #remove short word\n",
        "  data[col1] = data[col1].apply(lambda x: [word for word in x if len(word)>2])\n",
        "\n",
        "  #remove symbols\n",
        "  data[col1] = data[col1].apply (lambda x: [re.sub(r\"[^a-z]\", \"\", word) for word in x])\n",
        "\n",
        "  #lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  data[col1] = data[col1].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "\n",
        "\n",
        "  #Adding column2\n",
        "  #Lower the lettercase\n",
        "  data[col2] = data[col2].str.lower()\n",
        "\n",
        "  #Remove stop words\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  data[col2] = data[col2].apply(lambda x: \" \".join([word for word in str(x).split() if word not in (stop_words)]))\n",
        "\n",
        "  #remove symbols\n",
        "  data[col2] = data[col2].apply (lambda x: [re.sub(r\"[.,'?]\", \"\", x)])\n",
        "\n",
        "  return\n"
      ],
      "metadata": {
        "id": "WQ8V0kRFcjl8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data**"
      ],
      "metadata": {
        "id": "M-mVne19lMkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "QTDf9v7Eo31v",
        "outputId": "d472ece8-2711-46f6-849e-04c94a221796",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "JP Morgan QA section"
      ],
      "metadata": {
        "id": "tZx8UzN3QQt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining qa_data\n",
        "qa_data = pd.read_csv(\"/content/jpmorgan_qa_section.csv\")\n",
        "qa_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "9WD6Z5Tjfykz",
        "outputId": "e02110c7-0e3e-4440-a9de-6cc9e476215e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Analyst                 Analyst Role  \\\n",
              "0  Steven Chubak  Analyst, Wolfe Research LLC   \n",
              "1  Steven Chubak  Analyst, Wolfe Research LLC   \n",
              "2  Steven Chubak  Analyst, Wolfe Research LLC   \n",
              "3  Steven Chubak  Analyst, Wolfe Research LLC   \n",
              "4      Ken Usdin       Analyst, Jefferies LLC   \n",
              "\n",
              "                                            Question      Executive  \\\n",
              "0                                 Hey, good morning.  Jeremy Barnum   \n",
              "1  So, Jamie, I was actually hoping to get your p...    Jamie Dimon   \n",
              "2  Got it. And just in terms of appetite for the ...    Jamie Dimon   \n",
              "3                   ...elevated macro uncertainties.    Jamie Dimon   \n",
              "4  Hey, thanks. Good morning. Hey, Jeremy, I was ...  Jeremy Barnum   \n",
              "\n",
              "                                 Executive Role Type  \\\n",
              "0            Chief Financial Officer, JPMorgan Chase   \n",
              "1  Chairman & Chief Executive Officer, JPMorgan C...   \n",
              "2  Chairman & Chief Executive Officer, JPMorgan C...   \n",
              "3  Chairman & Chief Executive Officer, JPMorgan C...   \n",
              "4            Chief Financial Officer, JPMorgan Chase   \n",
              "\n",
              "                                            Response  \\\n",
              "0                               Good morning, Steve.   \n",
              "1  Well, I think you were already kind of complet...   \n",
              "2                                          Oh, yeah.   \n",
              "3  Well, we've told you that we're kind of pencil...   \n",
              "4  Yeah, sure. So let me just summarize the drive...   \n",
              "\n",
              "                       filename Quarter   call_date  \n",
              "0  1q23-earnings-transcript.pdf    1Q23  2023-04-14  \n",
              "1  1q23-earnings-transcript.pdf    1Q23  2023-04-14  \n",
              "2  1q23-earnings-transcript.pdf    1Q23  2023-04-14  \n",
              "3  1q23-earnings-transcript.pdf    1Q23  2023-04-14  \n",
              "4  1q23-earnings-transcript.pdf    1Q23  2023-04-14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e39d8ff4-ffce-4171-966a-0bea00ebbe0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Analyst</th>\n",
              "      <th>Analyst Role</th>\n",
              "      <th>Question</th>\n",
              "      <th>Executive</th>\n",
              "      <th>Executive Role Type</th>\n",
              "      <th>Response</th>\n",
              "      <th>filename</th>\n",
              "      <th>Quarter</th>\n",
              "      <th>call_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Steven Chubak</td>\n",
              "      <td>Analyst, Wolfe Research LLC</td>\n",
              "      <td>Hey, good morning.</td>\n",
              "      <td>Jeremy Barnum</td>\n",
              "      <td>Chief Financial Officer, JPMorgan Chase</td>\n",
              "      <td>Good morning, Steve.</td>\n",
              "      <td>1q23-earnings-transcript.pdf</td>\n",
              "      <td>1Q23</td>\n",
              "      <td>2023-04-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Steven Chubak</td>\n",
              "      <td>Analyst, Wolfe Research LLC</td>\n",
              "      <td>So, Jamie, I was actually hoping to get your p...</td>\n",
              "      <td>Jamie Dimon</td>\n",
              "      <td>Chairman &amp; Chief Executive Officer, JPMorgan C...</td>\n",
              "      <td>Well, I think you were already kind of complet...</td>\n",
              "      <td>1q23-earnings-transcript.pdf</td>\n",
              "      <td>1Q23</td>\n",
              "      <td>2023-04-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Steven Chubak</td>\n",
              "      <td>Analyst, Wolfe Research LLC</td>\n",
              "      <td>Got it. And just in terms of appetite for the ...</td>\n",
              "      <td>Jamie Dimon</td>\n",
              "      <td>Chairman &amp; Chief Executive Officer, JPMorgan C...</td>\n",
              "      <td>Oh, yeah.</td>\n",
              "      <td>1q23-earnings-transcript.pdf</td>\n",
              "      <td>1Q23</td>\n",
              "      <td>2023-04-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Steven Chubak</td>\n",
              "      <td>Analyst, Wolfe Research LLC</td>\n",
              "      <td>...elevated macro uncertainties.</td>\n",
              "      <td>Jamie Dimon</td>\n",
              "      <td>Chairman &amp; Chief Executive Officer, JPMorgan C...</td>\n",
              "      <td>Well, we've told you that we're kind of pencil...</td>\n",
              "      <td>1q23-earnings-transcript.pdf</td>\n",
              "      <td>1Q23</td>\n",
              "      <td>2023-04-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ken Usdin</td>\n",
              "      <td>Analyst, Jefferies LLC</td>\n",
              "      <td>Hey, thanks. Good morning. Hey, Jeremy, I was ...</td>\n",
              "      <td>Jeremy Barnum</td>\n",
              "      <td>Chief Financial Officer, JPMorgan Chase</td>\n",
              "      <td>Yeah, sure. So let me just summarize the drive...</td>\n",
              "      <td>1q23-earnings-transcript.pdf</td>\n",
              "      <td>1Q23</td>\n",
              "      <td>2023-04-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e39d8ff4-ffce-4171-966a-0bea00ebbe0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e39d8ff4-ffce-4171-966a-0bea00ebbe0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e39d8ff4-ffce-4171-966a-0bea00ebbe0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-799d4f81-8db0-453f-8999-cffeda8979dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-799d4f81-8db0-453f-8999-cffeda8979dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-799d4f81-8db0-453f-8999-cffeda8979dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "qa_data",
              "summary": "{\n  \"name\": \"qa_data\",\n  \"rows\": 143,\n  \"fields\": [\n    {\n      \"column\": \"Analyst\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"John McDonald\",\n          \"Ken Usdin\",\n          \"Ebrahim H. Poonawala\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Analyst Role\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Analyst, Autonomous Research\",\n          \"Analyst, Jefferies LLC\",\n          \"Analyst, Bank of America Merrill Lynch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 140,\n        \"samples\": [\n          \"Hey. Good morning. Jeremy, do you think there's any receptivity among regulators regarding the double counting not only of operational risk but I think you alluded to this earlier in the Markets business, but there's clearly double counting in market risk in the trading book. Is there any receptivity?\",\n          \"Okay. Got it. And then just to follow up to make it super clear on the idea of the Markets NII, that outlook being revised down by $1 billion but revenue neutral. I guess, the obvious thing is, there, there's typically an offset in fee income and you don't guide to that. But the idea would be the way you're structuring trades, the way the balance sheet is evolving, there's some offset that you'd expect in Markets fees from the lower Markets NII, correct?\",\n          \"That makes sense. And as a follow-up to that, on the Consumer side you mentioned that consumers continue to spend albeit a little more slowly, and you mentioned that consumers are also using their excess deposits a little bit more as well. Can you just elaborate a little bit more on just your feeling about the state of the consumer? And is that Card growth continue to be driven by people needing to revolve as opposed to wanting to have more in their deposits? Just kind of want the trade-off on that side too? 8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Executive\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Jamie Dimon\",\n          \"Jeremy Barnum\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Executive Role Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Chairman & Chief Executive Officer, JPMorgan Chase\",\n          \"Chief Financial Officer, JPMorgan Chase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 140,\n        \"samples\": [\n          \"Can I just answer that real quickly? We don't really know. It's a one-sided conversation generally. They say put it in your comments, so everyone is going to put in extensive comments, kind of like you heard from Jeremy and we don't really know. We don't really know what's going on inside the Fed, how many people get involved. In my view, it's become a very politicized process as opposed to the technical analysis I think is required to do it exactly right. So we'll see.\",\n          \"Yeah, John. So, in short, yes to both questions. So, yes, the relative lack of build this quarter is a function of the normal seasonal patterns of Card. Yes, we still expect 12% Card loan growth for the full year. And yes, that still means that all else equal, we think the consensus for the allowance build for the back three quarters is still a little too low, if you map it to that expected Card loan growth. Obviously, there's the wild card of what happens with our probabilities and our parameters and the output of our internal process of assessing the skew in the seasonal distribution and so on, and we're not speaking to that one way or the other. So, if guys have your own opinions about that, that's fine, but we're narrowly just saying that based on the Card loan growth that we expect and normal coverage ratios for that, we do expect build in the back half of the year.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"2q23-earnings-transcript.pdf\",\n          \"jpm-3q23-earnings-call-transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quarter\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"2Q23\",\n          \"3Q23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"call_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"2023-07-14\",\n          \"2023-10-13\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing data\n",
        "preprocessor(qa_data, \"Question\", \"question_tokenised_data\", \"Question_cleaned\")\n",
        "preprocessor(qa_data,\"Response\",\"answer_tokenised_data\",\"Response_cleaned\")\n",
        "\n",
        "#reorganise column\n",
        "qa_data=qa_data[[\"filename\",\"Quarter\",\"Question\",\"Question_cleaned\",\"Analyst\",\"Analyst Role\",\"Response\",\"Response_cleaned\",\"Executive\",\"Executive Role Type\"]]"
      ],
      "metadata": {
        "id": "FG3pmAvhs0Lk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize Roles\n",
        "for i in range(len(qa_data)):\n",
        "  if isinstance(qa_data.loc[i, \"Executive Role Type\"], str):\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Chairman & Chief Executive Officer, JPMorgan Chase\",\"CEO\", qa_data.loc[i, \"Executive Role Type\"])\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Chief Executive Officer, JPMorgan Chase\",\"CEO\", qa_data.loc[i, \"Executive Role Type\"])\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Vice Chairman, JPMorgan Chase\",\"Vice President\", qa_data.loc[i, \"Executive Role Type\"])\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Managing Director$\",\"Managing Director\", qa_data.loc[i, \"Executive Role Type\"])\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Head of Investor Relations, JPMorgan Chase\",\"Head of IR\", qa_data.loc[i, \"Executive Role Type\"])\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Chief Financial Officer, JPMorgan Chase\",\"CFO\", qa_data.loc[i, \"Executive Role Type\"])\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Chief Operating Officer, JPMorgan Chase\",\"COO\", qa_data.loc[i, \"Executive Role Type\"])\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Chief Financial Officer, JPMorganChase\",\"CFO\", qa_data.loc[i, \"Executive Role Type\"])\n",
        "    qa_data.loc[i, \"Executive Role Type\"] = re.sub(r\"Chairman & Chief Executive Officer, JPMorganChase\",\"CEO\", qa_data.loc[i, \"Executive Role Type\"])\n"
      ],
      "metadata": {
        "id": "iLxTIOaH88AL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(qa_data))"
      ],
      "metadata": {
        "id": "BDXH_Kxq3lhu",
        "outputId": "6bae1406-c8ba-4837-d51e-abfc3782c95b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if there is nill\n",
        "print(f'Check if there is nil values on DF: {qa_data.isnull().sum()}')"
      ],
      "metadata": {
        "id": "C1RfFTPyoW9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53b92a9-f525-432c-fc8e-41206aaa6ebf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check if there is nil values on DF: filename               0\n",
            "Quarter                0\n",
            "Question               0\n",
            "Question_cleaned       0\n",
            "Analyst                0\n",
            "Analyst Role           0\n",
            "Response               0\n",
            "Response_cleaned       0\n",
            "Executive              0\n",
            "Executive Role Type    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "JP morgan management discussion"
      ],
      "metadata": {
        "id": "LdI0csMaQO0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining jp morgan managment discussion dataframe\n",
        "jpmorgan_body_df=pd.read_csv(\"jpmorgan_management_discussion.csv\")\n",
        "jpmorgan_body_df.head()"
      ],
      "metadata": {
        "id": "aSnVuAbaONTi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "7a560ec0-d05e-4d51-b393-55601f5e2482"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'jpmorgan_management_discussion.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-4fe7ddf426a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#defining jp morgan managment discussion dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjpmorgan_body_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jpmorgan_management_discussion.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjpmorgan_body_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'jpmorgan_management_discussion.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning transcript\n",
        "preprocessor(jpmorgan_body_df, \"chunk_text\", \"tokenized_data\",\"cleaned_data\")"
      ],
      "metadata": {
        "id": "4-dmPqCeJZ4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpmorgan_body_df.head()"
      ],
      "metadata": {
        "id": "ALyMIKOHJvmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Export the output as a csv file**"
      ],
      "metadata": {
        "id": "189rbzkJzGY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "JP morgan QA section"
      ],
      "metadata": {
        "id": "tayihcvBmnCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#export preprocessed data\n",
        "preprocessed_qa_csv_path1 = \"/content/drive/MyDrive/bank_of_england/data/preprocessed_data/jpmorgan_qna_df_preprocessed_ver7.csv\"\n",
        "qa_data.to_csv(\"jp_morgan.csv\", index=False)"
      ],
      "metadata": {
        "id": "-n4tA2OZzOCc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "JP morgan management discussion"
      ],
      "metadata": {
        "id": "3_E9S1Wlmr5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#export preprocessed data\n",
        "preprocessed_qa_csv_path2 = \"/content/sample_data/jpmorgan_management_df_preprocessed.csv\"\n",
        "jpmorgan_body_df.to_csv(preprocessed_qa_csv_path2, index=False)"
      ],
      "metadata": {
        "id": "lplsq9lynDV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}