{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheldonkemper/bank_of_england/blob/main/notebooks/processed/sk_chunking_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjcWzjxiUs3i"
      },
      "source": [
        "Modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "===================================================\n",
        "Author: Sheldon Kemper\n",
        "Role: Data Engineering Lead, Bank of England Employer Project (Quant Collective)\n",
        "LinkedIn: https://www.linkedin.com/in/sheldon-kemper\n",
        "Date: 2025-02-04\n",
        "Version: 1.1\n",
        "\n",
        "Description:\n",
        "    This notebook implements a system for cleaning, chunking, and exporting transcript data\n",
        "    for the Bank of England project. The workflow reads a CSV file containing video transcripts\n",
        "    (with metadata such as filename, financial quarter, and call date), applies source‐specific\n",
        "    cleaning (e.g., removing header text in JP Morgan transcripts), and splits each transcript\n",
        "    into smaller chunks based on sentence boundaries (with a maximum chunk size of 500 characters).\n",
        "    Each chunk is annotated with its original filename, chunk index, financial quarter, and call date,\n",
        "    and then saved to a new CSV file. This processed, chunked data supports downstream modeling\n",
        "    tasks—such as topic modeling with BERTopic—and further analysis within our data engineering infrastructure.\n",
        "\n",
        "===================================================\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "vmX59-ASY-gE",
        "outputId": "b3cfa86a-96e9-4411-f21e-87eadf30c71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n===================================================\\nAuthor: Sheldon Kemper\\nRole: Data Engineering Lead, Bank of England Employer Project (Quant Collective)\\nLinkedIn: https://www.linkedin.com/in/sheldon-kemper\\nDate: 2025-02-04\\nVersion: 1.1\\n\\nDescription:\\n    This notebook implements a system for processing and converting video transcripts into a single CSV file\\n    for the Bank of England project. The workflow processes MP4 files stored in the raw data directory on Google Drive\\n    by using a machine learning-based speech-to-text model (e.g., OpenAI’s Whisper) to transcribe the audio content into text.\\n    Each transcript is appended as a record in the CSV file along with metadata—such as the year, quarter, and a duplicate indicator—\\n    which are inferred from the video file name. This pipeline supports the ongoing integration of transcripts across multiple\\n    quarters and years, facilitating further analysis and reporting within our data engineering infrastructure.\\n\\n===================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk bertopic sentence-transformers"
      ],
      "metadata": {
        "id": "zzujszK1ja3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install whisper (if not already installed)\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyCigYPknYBS",
        "outputId": "727ab01b-be1e-44b6-c388-7dab84a17f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-86pj5jpn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-86pj5jpn\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.61.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2->openai-whisper==20240930) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=1452f51d2f072824245a5b189ed14b95bc9026dc03e7571d1865b00b16bc86d1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-42254hv3/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyrdK8-KUs3l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VD8ipZFGbLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acea1e19-bc95-4c85-d30b-6783193ba134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "BOE Directory Contents: ['raw', 'processed', 'model', 'preprocessed_data']\n",
            "Raw Data Directory Contents: ['MP4.zip']\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to the root location with force_remount\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Assuming 'BOE' folder is in 'MyDrive' and already shared\n",
        "BOE_path = '/content/drive/MyDrive/BOE/bank_of_england/data'\n",
        "\n",
        "# List the contents of the BOE directory\n",
        "print(\"BOE Directory Contents:\", os.listdir(BOE_path))\n",
        "\n",
        "# Define the raw data path (assuming your audio files are under raw/santander)\n",
        "raw_data_path = os.path.join(BOE_path, 'raw', 'santander')\n",
        "print(\"Raw Data Directory Contents:\", os.listdir(raw_data_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the 'punkt_tab' resource is downloaded.\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def clean_transcript(text):\n",
        "    \"\"\"\n",
        "    Cleans the transcript text based on the source.\n",
        "\n",
        "    For JP Morgan transcripts, if the text contains the marker\n",
        "    \"MANAGEMENT DISCUSSION SECTION\", this function removes all content\n",
        "    before (and including) that marker.\n",
        "\n",
        "    For Santander transcripts (or any transcript without that marker),\n",
        "    the text is returned unchanged.\n",
        "    \"\"\"\n",
        "    marker = \"MANAGEMENT DISCUSSION SECTION\"\n",
        "    if marker in text:\n",
        "        parts = text.split(marker, 1)\n",
        "        cleaned_text = parts[1].strip()\n",
        "        return cleaned_text\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "def chunk_text(text, max_chunk_size=500):\n",
        "    \"\"\"\n",
        "    Splits the input text into chunks that do not exceed max_chunk_size characters.\n",
        "    The splitting is based on sentence boundaries.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The full text to be chunked.\n",
        "        max_chunk_size (int): Maximum number of characters per chunk.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of text chunks.\n",
        "    \"\"\"\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) + 1 > max_chunk_size:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "                current_chunk = sentence + \" \"\n",
        "            else:\n",
        "                chunks.append(sentence.strip())\n",
        "                current_chunk = \"\"\n",
        "        else:\n",
        "            current_chunk += sentence + \" \"\n",
        "    if current_chunk.strip():\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "zTmFN70TjxRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# Step 1: Load the transcript CSV file.\n",
        "# =====================================================\n",
        "\n",
        "location = \"/content/drive/MyDrive/BOE/bank_of_england/data/processed/\"\n",
        "filename = \"management_discussion.csv\"\n",
        "\n",
        "csv_file = f\"/{location}/{filename}\"\n",
        "expected_headers = [\"filename\", \"management_discussion\", \"financial_quarter\", \"call_date\"]\n",
        "\n",
        "if os.path.exists(csv_file):\n",
        "    print(f\"CSV file exists at: {csv_file}\")\n",
        "else:\n",
        "    print(f\"CSV file does not exist at: {csv_file}\")\n",
        "\n",
        "with open(csv_file, \"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    first_row = next(reader)\n",
        "    print(\"First row read from file:\", first_row)\n",
        "    if first_row == expected_headers:\n",
        "        f.seek(0)\n",
        "        dict_reader = csv.DictReader(f)\n",
        "    else:\n",
        "        print(\"Header does not match expected headers; using manual fieldnames and skipping first row.\")\n",
        "        f.seek(0)\n",
        "        dict_reader = csv.DictReader(f, fieldnames=expected_headers)\n",
        "        next(dict_reader)\n",
        "\n",
        "    transcripts = []\n",
        "    row_count = 0\n",
        "    for row in dict_reader:\n",
        "        row_count += 1\n",
        "        transcripts.append({\n",
        "            \"filename\": row.get(\"filename\", \"\").strip(),\n",
        "            \"management_discussion\": row.get(\"management_discussion\", \"\").strip(),\n",
        "            \"financial_quarter\": row.get(\"financial_quarter\", \"Unknown\").strip(),\n",
        "            \"call_date\": row.get(\"call_date\", \"Unknown\").strip()\n",
        "        })\n",
        "\n",
        "print(f\"Total rows loaded: {row_count}\")\n",
        "for i, t in enumerate(transcripts, start=1):\n",
        "    print(f\"Row {i}:\")\n",
        "    print(f\"  filename: {t['filename']}\")\n",
        "    print(f\"  financial_quarter: {t['financial_quarter']}\")\n",
        "    print(f\"  call_date: {t['call_date']}\")\n",
        "    print(f\"  Transcript length: {len(t['management_discussion'])}\")\n",
        "\n",
        "# =====================================================\n",
        "# Step 2: Clean and chunk each transcript, and save the chunked data.\n",
        "# =====================================================\n",
        "chunked_data = []  # This will store dictionaries with metadata for each chunk.\n",
        "for t in transcripts:\n",
        "    # Clean the transcript (e.g., remove JP Morgan headers if present).\n",
        "    cleaned_text = clean_transcript(t[\"management_discussion\"])\n",
        "    if cleaned_text:\n",
        "        chunks = chunk_text(cleaned_text, max_chunk_size=500)\n",
        "        if chunks:\n",
        "            for idx, chunk in enumerate(chunks, start=1):\n",
        "                chunked_data.append({\n",
        "                    \"filename\": t[\"filename\"],\n",
        "                    \"chunk_index\": idx,\n",
        "                    \"chunk_text\": chunk,\n",
        "                    \"financial_quarter\": t[\"financial_quarter\"],\n",
        "                    \"call_date\": t[\"call_date\"]\n",
        "                })\n",
        "        else:\n",
        "            print(f\"No chunks produced for {t['filename']}.\")\n",
        "    else:\n",
        "        print(f\"Transcript for {t['filename']} is empty after cleaning.\")\n",
        "\n",
        "print(f\"Total chunks obtained: {len(chunked_data)}\")\n",
        "\n",
        "# Save the chunked data to a new CSV file.\n",
        "chunked_csv_file = os.path.join(\"/content/drive/MyDrive/BOE/bank_of_england/data/processed\", f\"chunked_{filename}\")\n",
        "with open(chunked_csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    fieldnames = [\"filename\", \"chunk_index\", \"chunk_text\", \"financial_quarter\", \"call_date\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for row in chunked_data:\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(f\"Chunked data saved to {chunked_csv_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxWYeuco5Uxw",
        "outputId": "0bdda505-4894-4760-a02d-250923b71768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file exists at: //content/drive/MyDrive/BOE/bank_of_england/data/processed//management_discussion.csv\n",
            "First row read from file: ['filename', 'management_discussion', 'financial_quarter', 'call_date']\n",
            "Total rows loaded: 8\n",
            "Row 1:\n",
            "  filename: 4q24-earnings-transcript.pdf\n",
            "  financial_quarter: 4Q24\n",
            "  call_date: 2025-01-15\n",
            "  Transcript length: 13232\n",
            "Row 2:\n",
            "  filename: jpmc-third-quarter-2024-earnings-conference-call-transcript.pdf\n",
            "  financial_quarter: 3Q24\n",
            "  call_date: 2024-10-11\n",
            "  Transcript length: 9213\n",
            "Row 3:\n",
            "  filename: jpm-2q24-earnings-call-transcript-final.pdf\n",
            "  financial_quarter: 2Q24\n",
            "  call_date: 2024-07-12\n",
            "  Transcript length: 11025\n",
            "Row 4:\n",
            "  filename: jpm-1q24-earnings-call-transcript.pdf\n",
            "  financial_quarter: 1Q24\n",
            "  call_date: 2024-04-12\n",
            "  Transcript length: 11789\n",
            "Row 5:\n",
            "  filename: jpm-4q23-earnings-call-transcript.pdf\n",
            "  financial_quarter: 4Q23\n",
            "  call_date: 2024-01-12\n",
            "  Transcript length: 13699\n",
            "Row 6:\n",
            "  filename: jpm-3q23-earnings-call-transcript.pdf\n",
            "  financial_quarter: 3Q23\n",
            "  call_date: 2023-10-13\n",
            "  Transcript length: 15849\n",
            "Row 7:\n",
            "  filename: 2q23-earnings-transcript.pdf\n",
            "  financial_quarter: 2Q23\n",
            "  call_date: 2023-07-14\n",
            "  Transcript length: 13663\n",
            "Row 8:\n",
            "  filename: 1q23-earnings-transcript.pdf\n",
            "  financial_quarter: 1Q23\n",
            "  call_date: 2023-04-14\n",
            "  Transcript length: 13103\n",
            "Total chunks obtained: 239\n",
            "Chunked data saved to /content/drive/MyDrive/BOE/bank_of_england/data/processed/chunked_management_discussion.csv\n",
            "Topic Information:\n",
            "   Topic  Count                  Name  \\\n",
            "0      0    224     0_of_the_year_and   \n",
            "1      1     15  1_call_the_to_barnum   \n",
            "\n",
            "                                      Representation  \\\n",
            "0  [of, the, year, and, on, in, billion, to, up, by]   \n",
            "1  [call, the, to, barnum, jpmorgan, chase, chief...   \n",
            "\n",
            "                                 Representative_Docs  \n",
            "0  [Equity Markets was down 8%, driven by lower r...  \n",
            "1  [Operator: Good morning, ladies and gentlemen....  \n",
            "Chunk 1 assigned to topic: 1\n",
            "Chunk 2 assigned to topic: 1\n",
            "Chunk 3 assigned to topic: 0\n",
            "Chunk 4 assigned to topic: 0\n",
            "Chunk 5 assigned to topic: 0\n",
            "Chunk 6 assigned to topic: 0\n",
            "Chunk 7 assigned to topic: 0\n",
            "Chunk 8 assigned to topic: 0\n",
            "Chunk 9 assigned to topic: 0\n",
            "Chunk 10 assigned to topic: 0\n",
            "Chunk 11 assigned to topic: 0\n",
            "Chunk 12 assigned to topic: 0\n",
            "Chunk 13 assigned to topic: 0\n",
            "Chunk 14 assigned to topic: 0\n",
            "Chunk 15 assigned to topic: 0\n",
            "Chunk 16 assigned to topic: 0\n",
            "Chunk 17 assigned to topic: 0\n",
            "Chunk 18 assigned to topic: 0\n",
            "Chunk 19 assigned to topic: 0\n",
            "Chunk 20 assigned to topic: 0\n",
            "Chunk 21 assigned to topic: 0\n",
            "Chunk 22 assigned to topic: 0\n",
            "Chunk 23 assigned to topic: 0\n",
            "Chunk 24 assigned to topic: 0\n",
            "Chunk 25 assigned to topic: 0\n",
            "Chunk 26 assigned to topic: 0\n",
            "Chunk 27 assigned to topic: 0\n",
            "Chunk 28 assigned to topic: 1\n",
            "Chunk 29 assigned to topic: 0\n",
            "Chunk 30 assigned to topic: 1\n",
            "Chunk 31 assigned to topic: 1\n",
            "Chunk 32 assigned to topic: 1\n",
            "Chunk 33 assigned to topic: 0\n",
            "Chunk 34 assigned to topic: 0\n",
            "Chunk 35 assigned to topic: 0\n",
            "Chunk 36 assigned to topic: 0\n",
            "Chunk 37 assigned to topic: 0\n",
            "Chunk 38 assigned to topic: 0\n",
            "Chunk 39 assigned to topic: 0\n",
            "Chunk 40 assigned to topic: 0\n",
            "Chunk 41 assigned to topic: 0\n",
            "Chunk 42 assigned to topic: 0\n",
            "Chunk 43 assigned to topic: 0\n",
            "Chunk 44 assigned to topic: 0\n",
            "Chunk 45 assigned to topic: 0\n",
            "Chunk 46 assigned to topic: 0\n",
            "Chunk 47 assigned to topic: 0\n",
            "Chunk 48 assigned to topic: 0\n",
            "Chunk 49 assigned to topic: 0\n",
            "Chunk 50 assigned to topic: 0\n",
            "Chunk 51 assigned to topic: 0\n",
            "Chunk 52 assigned to topic: 0\n",
            "Chunk 53 assigned to topic: 1\n",
            "Chunk 54 assigned to topic: 1\n",
            "Chunk 55 assigned to topic: 0\n",
            "Chunk 56 assigned to topic: 0\n",
            "Chunk 57 assigned to topic: 0\n",
            "Chunk 58 assigned to topic: 0\n",
            "Chunk 59 assigned to topic: 0\n",
            "Chunk 60 assigned to topic: 0\n",
            "Chunk 61 assigned to topic: 0\n",
            "Chunk 62 assigned to topic: 0\n",
            "Chunk 63 assigned to topic: 0\n",
            "Chunk 64 assigned to topic: 0\n",
            "Chunk 65 assigned to topic: 0\n",
            "Chunk 66 assigned to topic: 0\n",
            "Chunk 67 assigned to topic: 0\n",
            "Chunk 68 assigned to topic: 0\n",
            "Chunk 69 assigned to topic: 0\n",
            "Chunk 70 assigned to topic: 0\n",
            "Chunk 71 assigned to topic: 0\n",
            "Chunk 72 assigned to topic: 0\n",
            "Chunk 73 assigned to topic: 0\n",
            "Chunk 74 assigned to topic: 0\n",
            "Chunk 75 assigned to topic: 0\n",
            "Chunk 76 assigned to topic: 0\n",
            "Chunk 77 assigned to topic: 0\n",
            "Chunk 78 assigned to topic: 0\n",
            "Chunk 79 assigned to topic: 0\n",
            "Chunk 80 assigned to topic: 1\n",
            "Chunk 81 assigned to topic: 0\n",
            "Chunk 82 assigned to topic: 0\n",
            "Chunk 83 assigned to topic: 0\n",
            "Chunk 84 assigned to topic: 0\n",
            "Chunk 85 assigned to topic: 0\n",
            "Chunk 86 assigned to topic: 0\n",
            "Chunk 87 assigned to topic: 0\n",
            "Chunk 88 assigned to topic: 0\n",
            "Chunk 89 assigned to topic: 0\n",
            "Chunk 90 assigned to topic: 0\n",
            "Chunk 91 assigned to topic: 0\n",
            "Chunk 92 assigned to topic: 0\n",
            "Chunk 93 assigned to topic: 0\n",
            "Chunk 94 assigned to topic: 0\n",
            "Chunk 95 assigned to topic: 0\n",
            "Chunk 96 assigned to topic: 0\n",
            "Chunk 97 assigned to topic: 0\n",
            "Chunk 98 assigned to topic: 0\n",
            "Chunk 99 assigned to topic: 0\n",
            "Chunk 100 assigned to topic: 0\n",
            "Chunk 101 assigned to topic: 0\n",
            "Chunk 102 assigned to topic: 0\n",
            "Chunk 103 assigned to topic: 0\n",
            "Chunk 104 assigned to topic: 0\n",
            "Chunk 105 assigned to topic: 0\n",
            "Chunk 106 assigned to topic: 0\n",
            "Chunk 107 assigned to topic: 1\n",
            "Chunk 108 assigned to topic: 0\n",
            "Chunk 109 assigned to topic: 0\n",
            "Chunk 110 assigned to topic: 0\n",
            "Chunk 111 assigned to topic: 0\n",
            "Chunk 112 assigned to topic: 0\n",
            "Chunk 113 assigned to topic: 0\n",
            "Chunk 114 assigned to topic: 0\n",
            "Chunk 115 assigned to topic: 0\n",
            "Chunk 116 assigned to topic: 0\n",
            "Chunk 117 assigned to topic: 0\n",
            "Chunk 118 assigned to topic: 0\n",
            "Chunk 119 assigned to topic: 0\n",
            "Chunk 120 assigned to topic: 0\n",
            "Chunk 121 assigned to topic: 0\n",
            "Chunk 122 assigned to topic: 0\n",
            "Chunk 123 assigned to topic: 0\n",
            "Chunk 124 assigned to topic: 0\n",
            "Chunk 125 assigned to topic: 0\n",
            "Chunk 126 assigned to topic: 0\n",
            "Chunk 127 assigned to topic: 0\n",
            "Chunk 128 assigned to topic: 0\n",
            "Chunk 129 assigned to topic: 0\n",
            "Chunk 130 assigned to topic: 0\n",
            "Chunk 131 assigned to topic: 0\n",
            "Chunk 132 assigned to topic: 0\n",
            "Chunk 133 assigned to topic: 0\n",
            "Chunk 134 assigned to topic: 0\n",
            "Chunk 135 assigned to topic: 0\n",
            "Chunk 136 assigned to topic: 0\n",
            "Chunk 137 assigned to topic: 0\n",
            "Chunk 138 assigned to topic: 0\n",
            "Chunk 139 assigned to topic: 1\n",
            "Chunk 140 assigned to topic: 1\n",
            "Chunk 141 assigned to topic: 1\n",
            "Chunk 142 assigned to topic: 0\n",
            "Chunk 143 assigned to topic: 0\n",
            "Chunk 144 assigned to topic: 0\n",
            "Chunk 145 assigned to topic: 0\n",
            "Chunk 146 assigned to topic: 0\n",
            "Chunk 147 assigned to topic: 0\n",
            "Chunk 148 assigned to topic: 0\n",
            "Chunk 149 assigned to topic: 0\n",
            "Chunk 150 assigned to topic: 0\n",
            "Chunk 151 assigned to topic: 0\n",
            "Chunk 152 assigned to topic: 0\n",
            "Chunk 153 assigned to topic: 0\n",
            "Chunk 154 assigned to topic: 0\n",
            "Chunk 155 assigned to topic: 0\n",
            "Chunk 156 assigned to topic: 0\n",
            "Chunk 157 assigned to topic: 0\n",
            "Chunk 158 assigned to topic: 0\n",
            "Chunk 159 assigned to topic: 0\n",
            "Chunk 160 assigned to topic: 0\n",
            "Chunk 161 assigned to topic: 0\n",
            "Chunk 162 assigned to topic: 0\n",
            "Chunk 163 assigned to topic: 0\n",
            "Chunk 164 assigned to topic: 0\n",
            "Chunk 165 assigned to topic: 0\n",
            "Chunk 166 assigned to topic: 0\n",
            "Chunk 167 assigned to topic: 0\n",
            "Chunk 168 assigned to topic: 0\n",
            "Chunk 169 assigned to topic: 0\n",
            "Chunk 170 assigned to topic: 0\n",
            "Chunk 171 assigned to topic: 0\n",
            "Chunk 172 assigned to topic: 0\n",
            "Chunk 173 assigned to topic: 0\n",
            "Chunk 174 assigned to topic: 0\n",
            "Chunk 175 assigned to topic: 0\n",
            "Chunk 176 assigned to topic: 1\n",
            "Chunk 177 assigned to topic: 0\n",
            "Chunk 178 assigned to topic: 0\n",
            "Chunk 179 assigned to topic: 0\n",
            "Chunk 180 assigned to topic: 0\n",
            "Chunk 181 assigned to topic: 0\n",
            "Chunk 182 assigned to topic: 0\n",
            "Chunk 183 assigned to topic: 0\n",
            "Chunk 184 assigned to topic: 0\n",
            "Chunk 185 assigned to topic: 0\n",
            "Chunk 186 assigned to topic: 0\n",
            "Chunk 187 assigned to topic: 0\n",
            "Chunk 188 assigned to topic: 0\n",
            "Chunk 189 assigned to topic: 0\n",
            "Chunk 190 assigned to topic: 0\n",
            "Chunk 191 assigned to topic: 0\n",
            "Chunk 192 assigned to topic: 0\n",
            "Chunk 193 assigned to topic: 0\n",
            "Chunk 194 assigned to topic: 0\n",
            "Chunk 195 assigned to topic: 0\n",
            "Chunk 196 assigned to topic: 0\n",
            "Chunk 197 assigned to topic: 0\n",
            "Chunk 198 assigned to topic: 0\n",
            "Chunk 199 assigned to topic: 0\n",
            "Chunk 200 assigned to topic: 0\n",
            "Chunk 201 assigned to topic: 0\n",
            "Chunk 202 assigned to topic: 0\n",
            "Chunk 203 assigned to topic: 0\n",
            "Chunk 204 assigned to topic: 0\n",
            "Chunk 205 assigned to topic: 0\n",
            "Chunk 206 assigned to topic: 0\n",
            "Chunk 207 assigned to topic: 0\n",
            "Chunk 208 assigned to topic: 1\n",
            "Chunk 209 assigned to topic: 0\n",
            "Chunk 210 assigned to topic: 0\n",
            "Chunk 211 assigned to topic: 0\n",
            "Chunk 212 assigned to topic: 0\n",
            "Chunk 213 assigned to topic: 0\n",
            "Chunk 214 assigned to topic: 0\n",
            "Chunk 215 assigned to topic: 0\n",
            "Chunk 216 assigned to topic: 0\n",
            "Chunk 217 assigned to topic: 0\n",
            "Chunk 218 assigned to topic: 0\n",
            "Chunk 219 assigned to topic: 0\n",
            "Chunk 220 assigned to topic: 0\n",
            "Chunk 221 assigned to topic: 0\n",
            "Chunk 222 assigned to topic: 0\n",
            "Chunk 223 assigned to topic: 0\n",
            "Chunk 224 assigned to topic: 0\n",
            "Chunk 225 assigned to topic: 0\n",
            "Chunk 226 assigned to topic: 0\n",
            "Chunk 227 assigned to topic: 0\n",
            "Chunk 228 assigned to topic: 0\n",
            "Chunk 229 assigned to topic: 0\n",
            "Chunk 230 assigned to topic: 0\n",
            "Chunk 231 assigned to topic: 0\n",
            "Chunk 232 assigned to topic: 0\n",
            "Chunk 233 assigned to topic: 0\n",
            "Chunk 234 assigned to topic: 0\n",
            "Chunk 235 assigned to topic: 0\n",
            "Chunk 236 assigned to topic: 0\n",
            "Chunk 237 assigned to topic: 0\n",
            "Chunk 238 assigned to topic: 0\n",
            "Chunk 239 assigned to topic: 0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}